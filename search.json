[
  {
    "objectID": "pothole_detection.html",
    "href": "pothole_detection.html",
    "title": "Pothole Detection 1",
    "section": "",
    "text": "&lt;!DOCTYPE html&gt;\n\n\n\n\n\n\nComputer Vision Project\n\n\nDepartment of Computer Engineering\n\n\nHacettepe University\n\n\nAnkara, Turkey\n\n\n\n\n\nFevzi KÄ±las 2200356822 Hacettepe University fevzi.kilas@hacettepe.edu.tr\n\nimport numpy as np\nimport cv2\nimport os\nimport random\nfrom ultralytics import YOLO\n\n\nvideo_folder = 'train/rgb'\n\nvideo_files = [f for f in os.listdir(video_folder) if os.path.isfile(os.path.join(video_folder, f))]\nnum_videos = len(video_files)\n\nprint(num_videos)\n\n373\n\n\n\nselected_videos = random.sample(video_files, 10)\n\nprint(\"Randomly select 10 video:\")\nfor video in selected_videos:\n    print(video)\n\nRandomly select 10 video:\n0038.mp4\n0328.mp4\n0233.mp4\n0006.mp4\n0317.mp4\n0516.mp4\n0223.mp4\n0055.mp4\n0035.mp4\n0010.mp4\n\n\n\ndef compute_flow(frame1, frame2):\n    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n    gray1 = cv2.GaussianBlur(gray1, (3, 3), 5)\n    gray2 = cv2.GaussianBlur(gray2, (3, 3), 5)\n    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, pyr_scale=0.75, levels=3, winsize=5, iterations=3, poly_n=10, poly_sigma=1.2, flags=0)\n    return flow\n\n\ndef get_motion_mask(flow_mag, motion_thresh=1, kernel=np.ones((7,7))):\n    motion_mask = np.uint8(flow_mag &gt; motion_thresh) * 255\n    motion_mask = cv2.erode(motion_mask, kernel, iterations=1)\n    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n    motion_mask = cv2.morphologyEx(motion_mask, cv2.MORPH_CLOSE, kernel, iterations=3)\n    return motion_mask\n\n\ndef compute_flow_histo(frame1, frame2):\n    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n    \n    # Apply Histogram Equalization and increase contrast\n    gray1 = cv2.equalizeHist(gray1)\n    gray2 = cv2.equalizeHist(gray2)\n\n    gray1 = cv2.GaussianBlur(gray1, (3, 3), 5)\n    gray2 = cv2.GaussianBlur(gray2, (3, 3), 5)\n    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, pyr_scale=0.75, levels=3, winsize=5, iterations=3, poly_n=10, poly_sigma=1.2, flags=0)\n    return flow\n\n\ndef apply_color_space_conversion(frame):\n    # Convert image to HSV color space\n    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n    \n    # Getting better contrast by taking the V (value) channel in color space\n    v_channel = hsv[:,:,2]\n    \n    # Apply histogram equalization\n    equalized_v_channel = cv2.equalizeHist(v_channel)\n    \n    # Reassemble\n    hsv[:,:,2] = equalized_v_channel\n    \n    # Converting from HSV to BGR\n    result_frame = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n    \n    return result_frame\n# KAYNAK: https://staff.fnwi.uva.nl/r.vandenboomgaard/ComputerVision/LectureNotes/IP/PointOperators/HistogramEqualization.html\n\n\nDense Optical Flow & Histogram Equalization\n\ndef process_video(video_path):\n    cap = cv2.VideoCapture(video_path)\n    ret, frame1 = cap.read()\n    \n    if not ret:\n        print(f\"Video {video_path} not found.\")\n        return\n    \n    while cap.isOpened():\n        ret, frame2 = cap.read()\n        ret, frame3 = cap.read()\n        if not ret:\n            break\n\n        # Calculating Dense Optical Flow\n        flow = compute_flow(frame1, frame2)\n        mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n\n        # Calculating Dense Optical Flow with Histogram Equalization\n        flow_histo = compute_flow_histo(frame1, frame3)\n        mag_histo, _ = cv2.cartToPolar(flow_histo[..., 0], flow_histo[..., 1])\n        \n        # Create motion mask\n        min_thresh = 0.3\n        max_thresh = 1\n        motion_thresh = np.c_[np.linspace(min_thresh, max_thresh, frame1.shape[0])].repeat(frame1.shape[1], axis=-1)\n        mask = get_motion_mask(mag, motion_thresh=motion_thresh)\n        \n        mask_histo = get_motion_mask(mag_histo, motion_thresh=motion_thresh)\n\n        frame_resized = cv2.resize(frame2, (640, 480))\n        mask_resized = cv2.resize(mask, (640, 480))\n\n        frame3_resized = cv2.resize(frame3, (640, 480))\n        mask_histo_resized = cv2.resize(mask_histo, (640, 480))\n        \n        # Results of Flow w/ Histogram Equalization\n        cv2.imshow(\"Frame\", frame_resized)\n        cv2.imshow(\"Motion Mask\", mask_resized)\n        cv2.imshow(\"Motion Mask Histo\", mask_histo_resized)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n        \n        frame1 = frame2\n\n    cap.release()\n    cv2.destroyAllWindows()\n\nfor video in selected_videos:\n    video_path = os.path.join(video_folder, video)\n    print(f\"{video} processing...\")\n    process_video(video_path)\n\n0215.mp4 processing...\n\n\n\n\nColor space transformation process\n\ndef process_video(video_path):\n    cap = cv2.VideoCapture(video_path)\n    ret, frame1 = cap.read()\n    \n    if not ret:\n        print(f\"Video {video_path} not found.\")\n        return\n    \n    while cap.isOpened():\n        ret, frame2 = cap.read()\n        if not ret:\n            break\n\n        # Color space transformation process\n        processed_frame1 = apply_color_space_conversion(frame1)\n        processed_frame2 = apply_color_space_conversion(frame2)\n\n        # Detection\n        # detected_frame2 = detect_objects(processed_frame2)\n\n        # Calculating Dense Optical Flow\n        flow = compute_flow_histo(processed_frame1, processed_frame2)\n        mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n\n        # Create motion mask\n        min_thresh = 0.3\n        max_thresh = 1\n        motion_thresh = np.c_[np.linspace(min_thresh, max_thresh, frame1.shape[0])].repeat(frame1.shape[1], axis=-1)\n        mask = get_motion_mask(mag, motion_thresh=motion_thresh)\n\n        # Resize frames and mask\n        frame1_resized = cv2.resize(frame1, (640, 480))\n        frame2_resized = cv2.resize(frame2, (640, 480))\n        processed_frame2_resized = cv2.resize(processed_frame2, (640, 480))\n        mask_resized = cv2.resize(mask, (640, 480))\n\n        # Results\n        cv2.imshow(\"Original Frame\", frame1_resized)\n        cv2.imshow(\"Color space transformed Frame\", processed_frame2_resized)\n        cv2.imshow(\"Motion Mask\", mask_resized)\n        \n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n        \n        frame1 = frame2\n\n    cap.release\n\n    cap.release()\n    cv2.destroyAllWindows()\n\nfor video in selected_videos:\n    video_path = os.path.join(video_folder, video)\n    print(f\"{video} processing...\")\n    process_video(video_path)\n\n0328.mp4 processing...\n0215.mp4 processing...\n0554.mp4 processing...\n0516.mp4 processing...\n0134.mp4 processing...\n0328.mp4 processing...\n0325.mp4 processing...\n\n\n\n\nNon-Maximum Supression & Detection\n\nmodel = YOLO(\"seg_v1.pt\")\n\n\ndef detect_objects(frame):\n    # Call YOLO model for output and get the output\n    results = model.predict(frame)\n    \n    # process boxes in predictions\n    for result in results:\n        for bbox in result.boxes.xyxy:\n            # Check the boxes\n            x1, y1, x2, y2 = map(int, bbox)\n            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n            text = f\"Class: Pothole\"\n            cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n    return frame\n\ndef get_motion_mask_x(magnitude, motion_thresh):\n    mask = np.zeros_like(magnitude, dtype=np.uint8)\n    mask[magnitude &gt; motion_thresh] = 255\n    return mask\n\ndef non_maximum_suppression(mask, kernel_size=5):\n    dilated = cv2.dilate(mask, np.ones((kernel_size, kernel_size), np.uint8))\n    nms_mask = (mask == dilated) & (mask &gt; 0)\n    return nms_mask.astype(np.uint8) * 255\n\ndef process_video(video_path):\n    cap = cv2.VideoCapture(video_path)\n    ret, frame1 = cap.read()\n    \n    if not ret:\n        print(f\"Video {video_path} not found.\")\n        return\n    \n    frame1 = apply_color_space_conversion(frame1)\n    while cap.isOpened():\n        ret, frame2 = cap.read()\n        if not ret:\n            break\n\n        processed_frame2 = apply_color_space_conversion(frame2)\n        detected_frame = detect_objects(frame1)\n        flow = compute_flow_histo(frame1, processed_frame2)\n        mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n\n        min_thresh = 0.3\n        max_thresh = 1\n        motion_thresh = np.c_[np.linspace(min_thresh, max_thresh, frame1.shape[0])].repeat(frame1.shape[1], axis=-1)\n        mask = get_motion_mask(mag, motion_thresh=motion_thresh)\n        mask_x = get_motion_mask_x(mag, motion_thresh=motion_thresh)\n\n        nms_mask = non_maximum_suppression(mask_x)\n\n        processed_frame2_resized = cv2.resize(processed_frame2, (640, 480))\n        mask_resized = cv2.resize(mask, (640, 480))\n        nms_mask_resized = cv2.resize(nms_mask, (640, 480))\n        detected_frame_resized = cv2.resize(detected_frame, (640, 480))\n\n        cv2.imshow(\"Processed Frame\", processed_frame2_resized)\n        cv2.imshow(\"Motion Mask\", mask_resized)\n        cv2.imshow(\"NMS Motion Mask\", nms_mask_resized)\n        cv2.imshow(\"DETECTIOM\",detected_frame_resized)\n        \n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n        \n        frame1 = frame2\n\n    cap.release()\n    cv2.destroyAllWindows()\n\n\nfor video in selected_videos:\n    video_path = os.path.join(video_folder, video)\n    print(f\"{video} processing...\")\n    process_video(video_path)\n\n0328.mp4 processing...\n\n0: 512x512 6 Potholes, 324.5ms\nSpeed: 6.0ms preprocess, 324.5ms inference, 27.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 343.2ms\nSpeed: 4.0ms preprocess, 343.2ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 347.3ms\nSpeed: 5.0ms preprocess, 347.3ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 379.0ms\nSpeed: 5.0ms preprocess, 379.0ms inference, 11.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 337.6ms\nSpeed: 6.1ms preprocess, 337.6ms inference, 8.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 335.7ms\nSpeed: 6.0ms preprocess, 335.7ms inference, 9.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 342.8ms\nSpeed: 4.0ms preprocess, 342.8ms inference, 11.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 356.2ms\nSpeed: 6.0ms preprocess, 356.2ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 378.3ms\nSpeed: 8.0ms preprocess, 378.3ms inference, 8.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 340.2ms\nSpeed: 6.5ms preprocess, 340.2ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 332.6ms\nSpeed: 6.6ms preprocess, 332.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 321.8ms\nSpeed: 5.6ms preprocess, 321.8ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 333.5ms\nSpeed: 5.0ms preprocess, 333.5ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 331.4ms\nSpeed: 4.0ms preprocess, 331.4ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 333.9ms\nSpeed: 5.0ms preprocess, 333.9ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 336.1ms\nSpeed: 4.0ms preprocess, 336.1ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 349.1ms\nSpeed: 5.0ms preprocess, 349.1ms inference, 12.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 357.7ms\nSpeed: 6.0ms preprocess, 357.7ms inference, 11.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 330.2ms\nSpeed: 5.0ms preprocess, 330.2ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 335.4ms\nSpeed: 6.0ms preprocess, 335.4ms inference, 5.9ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 372.2ms\nSpeed: 4.0ms preprocess, 372.2ms inference, 16.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 335.0ms\nSpeed: 5.0ms preprocess, 335.0ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 335.3ms\nSpeed: 5.1ms preprocess, 335.3ms inference, 11.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 331.6ms\nSpeed: 6.0ms preprocess, 331.6ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 318.7ms\nSpeed: 3.0ms preprocess, 318.7ms inference, 9.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 368.1ms\nSpeed: 4.0ms preprocess, 368.1ms inference, 12.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 336.3ms\nSpeed: 5.0ms preprocess, 336.3ms inference, 18.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 333.4ms\nSpeed: 5.0ms preprocess, 333.4ms inference, 14.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 372.7ms\nSpeed: 7.0ms preprocess, 372.7ms inference, 12.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 331.6ms\nSpeed: 5.0ms preprocess, 331.6ms inference, 9.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 352.3ms\nSpeed: 4.0ms preprocess, 352.3ms inference, 11.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 384.2ms\nSpeed: 7.0ms preprocess, 384.2ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 350.2ms\nSpeed: 3.0ms preprocess, 350.2ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 352.4ms\nSpeed: 7.0ms preprocess, 352.4ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 339.3ms\nSpeed: 7.0ms preprocess, 339.3ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 343.4ms\nSpeed: 7.0ms preprocess, 343.4ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 333.5ms\nSpeed: 4.0ms preprocess, 333.5ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 344.6ms\nSpeed: 5.0ms preprocess, 344.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 341.7ms\nSpeed: 7.0ms preprocess, 341.7ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 336.5ms\nSpeed: 5.5ms preprocess, 336.5ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 332.2ms\nSpeed: 4.0ms preprocess, 332.2ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 374.2ms\nSpeed: 6.0ms preprocess, 374.2ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 320.6ms\nSpeed: 6.0ms preprocess, 320.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 335.1ms\nSpeed: 4.0ms preprocess, 335.1ms inference, 9.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 330.1ms\nSpeed: 4.0ms preprocess, 330.1ms inference, 11.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 360.3ms\nSpeed: 4.0ms preprocess, 360.3ms inference, 4.9ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 347.1ms\nSpeed: 5.0ms preprocess, 347.1ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n0215.mp4 processing...\n\n0: 512x512 1 Pothole, 327.6ms\nSpeed: 4.0ms preprocess, 327.6ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 321.1ms\nSpeed: 6.0ms preprocess, 321.1ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 347.8ms\nSpeed: 6.0ms preprocess, 347.8ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 361.0ms\nSpeed: 6.0ms preprocess, 361.0ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 331.5ms\nSpeed: 6.0ms preprocess, 331.5ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 353.1ms\nSpeed: 4.0ms preprocess, 353.1ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 344.9ms\nSpeed: 4.0ms preprocess, 344.9ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 342.5ms\nSpeed: 6.0ms preprocess, 342.5ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 344.6ms\nSpeed: 5.0ms preprocess, 344.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 374.8ms\nSpeed: 5.0ms preprocess, 374.8ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 334.8ms\nSpeed: 6.0ms preprocess, 334.8ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 371.2ms\nSpeed: 9.0ms preprocess, 371.2ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 342.6ms\nSpeed: 4.0ms preprocess, 342.6ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 320.9ms\nSpeed: 4.0ms preprocess, 320.9ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 333.2ms\nSpeed: 6.0ms preprocess, 333.2ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 337.5ms\nSpeed: 5.0ms preprocess, 337.5ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 382.1ms\nSpeed: 7.0ms preprocess, 382.1ms inference, 6.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 335.8ms\nSpeed: 6.0ms preprocess, 335.8ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 321.1ms\nSpeed: 4.0ms preprocess, 321.1ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 343.3ms\nSpeed: 7.0ms preprocess, 343.3ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 320.7ms\nSpeed: 4.0ms preprocess, 320.7ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 324.7ms\nSpeed: 6.0ms preprocess, 324.7ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 337.2ms\nSpeed: 5.5ms preprocess, 337.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 391.2ms\nSpeed: 4.0ms preprocess, 391.2ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 349.1ms\nSpeed: 6.0ms preprocess, 349.1ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 412.1ms\nSpeed: 3.5ms preprocess, 412.1ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 356.2ms\nSpeed: 5.0ms preprocess, 356.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 334.6ms\nSpeed: 9.0ms preprocess, 334.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 318.1ms\nSpeed: 6.0ms preprocess, 318.1ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 336.2ms\nSpeed: 6.0ms preprocess, 336.2ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 320.4ms\nSpeed: 5.0ms preprocess, 320.4ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 344.7ms\nSpeed: 6.0ms preprocess, 344.7ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 319.8ms\nSpeed: 6.0ms preprocess, 319.8ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 335.9ms\nSpeed: 4.0ms preprocess, 335.9ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 330.6ms\nSpeed: 6.0ms preprocess, 330.6ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 326.3ms\nSpeed: 4.0ms preprocess, 326.3ms inference, 5.2ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 318.6ms\nSpeed: 4.4ms preprocess, 318.6ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 325.2ms\nSpeed: 5.0ms preprocess, 325.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 317.9ms\nSpeed: 7.0ms preprocess, 317.9ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 334.6ms\nSpeed: 5.0ms preprocess, 334.6ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 339.6ms\nSpeed: 4.0ms preprocess, 339.6ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 348.6ms\nSpeed: 4.0ms preprocess, 348.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 328.1ms\nSpeed: 4.0ms preprocess, 328.1ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 322.2ms\nSpeed: 4.0ms preprocess, 322.2ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 323.2ms\nSpeed: 3.5ms preprocess, 323.2ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 325.3ms\nSpeed: 5.0ms preprocess, 325.3ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 332.5ms\nSpeed: 5.0ms preprocess, 332.5ms inference, 6.4ms postprocess per image at shape (1, 3, 512, 512)\n0554.mp4 processing...\n\n0: 512x512 1 Pothole, 322.0ms\nSpeed: 4.0ms preprocess, 322.0ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 339.3ms\nSpeed: 7.0ms preprocess, 339.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 334.6ms\nSpeed: 5.0ms preprocess, 334.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 357.0ms\nSpeed: 4.0ms preprocess, 357.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 336.8ms\nSpeed: 4.1ms preprocess, 336.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 332.1ms\nSpeed: 12.0ms preprocess, 332.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 343.5ms\nSpeed: 6.0ms preprocess, 343.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 346.6ms\nSpeed: 5.0ms preprocess, 346.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 333.6ms\nSpeed: 6.0ms preprocess, 333.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 369.1ms\nSpeed: 7.5ms preprocess, 369.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 327.7ms\nSpeed: 4.0ms preprocess, 327.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 329.7ms\nSpeed: 6.0ms preprocess, 329.7ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 315.3ms\nSpeed: 4.0ms preprocess, 315.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 374.5ms\nSpeed: 7.0ms preprocess, 374.5ms inference, 6.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 338.1ms\nSpeed: 7.0ms preprocess, 338.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 362.2ms\nSpeed: 7.0ms preprocess, 362.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 337.2ms\nSpeed: 8.0ms preprocess, 337.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 347.2ms\nSpeed: 5.0ms preprocess, 347.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 314.5ms\nSpeed: 6.0ms preprocess, 314.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 334.0ms\nSpeed: 5.0ms preprocess, 334.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 331.6ms\nSpeed: 5.1ms preprocess, 331.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 340.5ms\nSpeed: 5.0ms preprocess, 340.5ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 326.2ms\nSpeed: 5.0ms preprocess, 326.2ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 344.4ms\nSpeed: 6.0ms preprocess, 344.4ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 352.7ms\nSpeed: 4.0ms preprocess, 352.7ms inference, 8.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 324.7ms\nSpeed: 4.5ms preprocess, 324.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 327.7ms\nSpeed: 4.0ms preprocess, 327.7ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 337.6ms\nSpeed: 5.0ms preprocess, 337.6ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 334.7ms\nSpeed: 4.0ms preprocess, 334.7ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 312.6ms\nSpeed: 4.0ms preprocess, 312.6ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 319.8ms\nSpeed: 6.0ms preprocess, 319.8ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 350.3ms\nSpeed: 6.0ms preprocess, 350.3ms inference, 8.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 345.3ms\nSpeed: 5.0ms preprocess, 345.3ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 321.4ms\nSpeed: 4.0ms preprocess, 321.4ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 321.7ms\nSpeed: 4.9ms preprocess, 321.7ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 329.9ms\nSpeed: 4.0ms preprocess, 329.9ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 327.7ms\nSpeed: 5.5ms preprocess, 327.7ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 356.6ms\nSpeed: 4.0ms preprocess, 356.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 322.1ms\nSpeed: 4.0ms preprocess, 322.1ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 334.6ms\nSpeed: 5.0ms preprocess, 334.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 325.7ms\nSpeed: 4.0ms preprocess, 325.7ms inference, 6.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 329.7ms\nSpeed: 5.5ms preprocess, 329.7ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 390.3ms\nSpeed: 5.0ms preprocess, 390.3ms inference, 6.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 318.1ms\nSpeed: 5.0ms preprocess, 318.1ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 340.5ms\nSpeed: 5.0ms preprocess, 340.5ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 340.7ms\nSpeed: 4.0ms preprocess, 340.7ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 342.5ms\nSpeed: 6.0ms preprocess, 342.5ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n0516.mp4 processing...\n\n0: 512x512 (no detections), 340.8ms\nSpeed: 4.0ms preprocess, 340.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 350.1ms\nSpeed: 6.0ms preprocess, 350.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 335.0ms\nSpeed: 5.0ms preprocess, 335.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 354.2ms\nSpeed: 4.0ms preprocess, 354.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 356.8ms\nSpeed: 6.0ms preprocess, 356.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 343.6ms\nSpeed: 4.0ms preprocess, 343.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 349.9ms\nSpeed: 5.5ms preprocess, 349.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 316.6ms\nSpeed: 7.0ms preprocess, 316.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 351.9ms\nSpeed: 5.0ms preprocess, 351.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 326.4ms\nSpeed: 6.0ms preprocess, 326.4ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 329.2ms\nSpeed: 6.0ms preprocess, 329.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 330.4ms\nSpeed: 6.0ms preprocess, 330.4ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 348.3ms\nSpeed: 6.0ms preprocess, 348.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 372.5ms\nSpeed: 5.0ms preprocess, 372.5ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 392.5ms\nSpeed: 3.0ms preprocess, 392.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 329.5ms\nSpeed: 6.0ms preprocess, 329.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 339.2ms\nSpeed: 5.0ms preprocess, 339.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 347.6ms\nSpeed: 6.0ms preprocess, 347.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 319.4ms\nSpeed: 5.0ms preprocess, 319.4ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 336.2ms\nSpeed: 4.0ms preprocess, 336.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 317.6ms\nSpeed: 6.0ms preprocess, 317.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 361.7ms\nSpeed: 4.0ms preprocess, 361.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 321.2ms\nSpeed: 6.0ms preprocess, 321.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 324.0ms\nSpeed: 5.0ms preprocess, 324.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 348.3ms\nSpeed: 5.0ms preprocess, 348.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 350.9ms\nSpeed: 4.0ms preprocess, 350.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 322.5ms\nSpeed: 6.0ms preprocess, 322.5ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 321.7ms\nSpeed: 6.0ms preprocess, 321.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 332.2ms\nSpeed: 4.0ms preprocess, 332.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 327.8ms\nSpeed: 6.0ms preprocess, 327.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 340.9ms\nSpeed: 5.0ms preprocess, 340.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 330.1ms\nSpeed: 7.0ms preprocess, 330.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 332.7ms\nSpeed: 5.0ms preprocess, 332.7ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 308.2ms\nSpeed: 4.0ms preprocess, 308.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 349.1ms\nSpeed: 5.0ms preprocess, 349.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 316.2ms\nSpeed: 5.1ms preprocess, 316.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 341.1ms\nSpeed: 4.0ms preprocess, 341.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 327.3ms\nSpeed: 5.0ms preprocess, 327.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 326.3ms\nSpeed: 4.0ms preprocess, 326.3ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 334.7ms\nSpeed: 5.0ms preprocess, 334.7ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 312.7ms\nSpeed: 4.0ms preprocess, 312.7ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 339.6ms\nSpeed: 5.0ms preprocess, 339.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 358.3ms\nSpeed: 4.0ms preprocess, 358.3ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 368.7ms\nSpeed: 4.9ms preprocess, 368.7ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 361.5ms\nSpeed: 4.0ms preprocess, 361.5ms inference, 8.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 335.2ms\nSpeed: 6.0ms preprocess, 335.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 336.7ms\nSpeed: 5.0ms preprocess, 336.7ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n0134.mp4 processing...\n\n0: 512x512 (no detections), 323.6ms\nSpeed: 4.0ms preprocess, 323.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 361.3ms\nSpeed: 7.0ms preprocess, 361.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 330.6ms\nSpeed: 4.2ms preprocess, 330.6ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 319.8ms\nSpeed: 4.0ms preprocess, 319.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 327.7ms\nSpeed: 5.0ms preprocess, 327.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 317.4ms\nSpeed: 7.1ms preprocess, 317.4ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 333.0ms\nSpeed: 5.0ms preprocess, 333.0ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 308.8ms\nSpeed: 4.0ms preprocess, 308.8ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 335.3ms\nSpeed: 4.0ms preprocess, 335.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 353.1ms\nSpeed: 4.0ms preprocess, 353.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 328.8ms\nSpeed: 4.0ms preprocess, 328.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 322.3ms\nSpeed: 5.5ms preprocess, 322.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 311.7ms\nSpeed: 7.0ms preprocess, 311.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 368.6ms\nSpeed: 6.1ms preprocess, 368.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 329.8ms\nSpeed: 6.0ms preprocess, 329.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 325.8ms\nSpeed: 5.0ms preprocess, 325.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 315.0ms\nSpeed: 5.0ms preprocess, 315.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 331.8ms\nSpeed: 3.0ms preprocess, 331.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 323.3ms\nSpeed: 4.9ms preprocess, 323.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 319.8ms\nSpeed: 5.0ms preprocess, 319.8ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 338.6ms\nSpeed: 5.0ms preprocess, 338.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 323.8ms\nSpeed: 4.0ms preprocess, 323.8ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 324.1ms\nSpeed: 5.0ms preprocess, 324.1ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 336.3ms\nSpeed: 4.0ms preprocess, 336.3ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 321.2ms\nSpeed: 7.0ms preprocess, 321.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 332.6ms\nSpeed: 6.0ms preprocess, 332.6ms inference, 4.9ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 343.8ms\nSpeed: 5.0ms preprocess, 343.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 319.9ms\nSpeed: 6.0ms preprocess, 319.9ms inference, 6.9ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 359.5ms\nSpeed: 7.0ms preprocess, 359.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 330.5ms\nSpeed: 4.0ms preprocess, 330.5ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 330.5ms\nSpeed: 5.0ms preprocess, 330.5ms inference, 6.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 317.6ms\nSpeed: 4.0ms preprocess, 317.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 409.6ms\nSpeed: 5.0ms preprocess, 409.6ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 310.2ms\nSpeed: 4.0ms preprocess, 310.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 314.2ms\nSpeed: 4.0ms preprocess, 314.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 311.8ms\nSpeed: 5.0ms preprocess, 311.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 328.7ms\nSpeed: 4.0ms preprocess, 328.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 362.7ms\nSpeed: 5.0ms preprocess, 362.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 381.7ms\nSpeed: 5.0ms preprocess, 381.7ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 355.5ms\nSpeed: 7.0ms preprocess, 355.5ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 359.8ms\nSpeed: 6.0ms preprocess, 359.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 321.5ms\nSpeed: 7.0ms preprocess, 321.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 326.2ms\nSpeed: 7.0ms preprocess, 326.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 320.3ms\nSpeed: 7.0ms preprocess, 320.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 340.8ms\nSpeed: 4.0ms preprocess, 340.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 334.1ms\nSpeed: 4.0ms preprocess, 334.1ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 (no detections), 331.2ms\nSpeed: 4.0ms preprocess, 331.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 512)\n0328.mp4 processing...\n\n0: 512x512 6 Potholes, 292.6ms\nSpeed: 4.0ms preprocess, 292.6ms inference, 23.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 306.6ms\nSpeed: 6.0ms preprocess, 306.6ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 329.7ms\nSpeed: 5.0ms preprocess, 329.7ms inference, 9.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 330.3ms\nSpeed: 6.1ms preprocess, 330.3ms inference, 9.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 345.7ms\nSpeed: 5.0ms preprocess, 345.7ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 321.0ms\nSpeed: 5.0ms preprocess, 321.0ms inference, 9.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 321.5ms\nSpeed: 3.0ms preprocess, 321.5ms inference, 9.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 321.7ms\nSpeed: 4.9ms preprocess, 321.7ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 317.5ms\nSpeed: 7.0ms preprocess, 317.5ms inference, 4.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 321.6ms\nSpeed: 5.0ms preprocess, 321.6ms inference, 11.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 331.5ms\nSpeed: 4.0ms preprocess, 331.5ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 324.3ms\nSpeed: 5.0ms preprocess, 324.3ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 326.7ms\nSpeed: 5.0ms preprocess, 326.7ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 349.6ms\nSpeed: 4.0ms preprocess, 349.6ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 332.6ms\nSpeed: 5.0ms preprocess, 332.6ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 336.3ms\nSpeed: 7.0ms preprocess, 336.3ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 332.7ms\nSpeed: 4.0ms preprocess, 332.7ms inference, 9.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 355.5ms\nSpeed: 4.0ms preprocess, 355.5ms inference, 8.4ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 382.7ms\nSpeed: 5.5ms preprocess, 382.7ms inference, 4.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 323.0ms\nSpeed: 6.0ms preprocess, 323.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 338.2ms\nSpeed: 5.0ms preprocess, 338.2ms inference, 11.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 335.4ms\nSpeed: 4.0ms preprocess, 335.4ms inference, 6.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 336.3ms\nSpeed: 6.0ms preprocess, 336.3ms inference, 8.7ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 365.7ms\nSpeed: 4.5ms preprocess, 365.7ms inference, 8.4ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 381.3ms\nSpeed: 6.0ms preprocess, 381.3ms inference, 13.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 355.2ms\nSpeed: 5.0ms preprocess, 355.2ms inference, 9.2ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 312.4ms\nSpeed: 4.0ms preprocess, 312.4ms inference, 14.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 321.7ms\nSpeed: 6.0ms preprocess, 321.7ms inference, 16.9ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 346.3ms\nSpeed: 6.5ms preprocess, 346.3ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 332.3ms\nSpeed: 5.0ms preprocess, 332.3ms inference, 11.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 332.1ms\nSpeed: 6.0ms preprocess, 332.1ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 350.5ms\nSpeed: 9.0ms preprocess, 350.5ms inference, 8.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 346.6ms\nSpeed: 4.0ms preprocess, 346.6ms inference, 9.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 332.4ms\nSpeed: 4.0ms preprocess, 332.4ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 356.2ms\nSpeed: 4.0ms preprocess, 356.2ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 330.5ms\nSpeed: 4.0ms preprocess, 330.5ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 340.9ms\nSpeed: 4.0ms preprocess, 340.9ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 329.0ms\nSpeed: 6.0ms preprocess, 329.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 380.5ms\nSpeed: 6.0ms preprocess, 380.5ms inference, 9.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 335.5ms\nSpeed: 4.0ms preprocess, 335.5ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 333.6ms\nSpeed: 5.0ms preprocess, 333.6ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 328.7ms\nSpeed: 6.0ms preprocess, 328.7ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 326.9ms\nSpeed: 9.6ms preprocess, 326.9ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 353.1ms\nSpeed: 5.0ms preprocess, 353.1ms inference, 9.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 322.3ms\nSpeed: 5.0ms preprocess, 322.3ms inference, 9.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 361.4ms\nSpeed: 6.0ms preprocess, 361.4ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 327.6ms\nSpeed: 4.0ms preprocess, 327.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n0325.mp4 processing...\n\n0: 512x512 2 Potholes, 329.4ms\nSpeed: 7.0ms preprocess, 329.4ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 336.3ms\nSpeed: 4.0ms preprocess, 336.3ms inference, 11.9ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 332.2ms\nSpeed: 5.0ms preprocess, 332.2ms inference, 17.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 322.8ms\nSpeed: 4.0ms preprocess, 322.8ms inference, 18.7ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 322.7ms\nSpeed: 7.0ms preprocess, 322.7ms inference, 14.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 328.2ms\nSpeed: 5.9ms preprocess, 328.2ms inference, 19.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 337.7ms\nSpeed: 5.0ms preprocess, 337.7ms inference, 17.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 332.4ms\nSpeed: 5.0ms preprocess, 332.4ms inference, 17.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 349.2ms\nSpeed: 5.0ms preprocess, 349.2ms inference, 16.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 328.0ms\nSpeed: 5.0ms preprocess, 328.0ms inference, 9.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 337.3ms\nSpeed: 5.0ms preprocess, 337.3ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 338.3ms\nSpeed: 6.0ms preprocess, 338.3ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 336.4ms\nSpeed: 6.0ms preprocess, 336.4ms inference, 17.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 5 Potholes, 357.0ms\nSpeed: 5.0ms preprocess, 357.0ms inference, 20.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 5 Potholes, 342.8ms\nSpeed: 6.0ms preprocess, 342.8ms inference, 21.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 330.7ms\nSpeed: 4.0ms preprocess, 330.7ms inference, 18.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 5 Potholes, 332.3ms\nSpeed: 6.0ms preprocess, 332.3ms inference, 19.6ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 346.6ms\nSpeed: 4.1ms preprocess, 346.6ms inference, 18.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 334.6ms\nSpeed: 5.0ms preprocess, 334.6ms inference, 17.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 334.7ms\nSpeed: 3.5ms preprocess, 334.7ms inference, 13.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 358.1ms\nSpeed: 6.0ms preprocess, 358.1ms inference, 21.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 346.4ms\nSpeed: 6.0ms preprocess, 346.4ms inference, 16.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 338.5ms\nSpeed: 6.0ms preprocess, 338.5ms inference, 16.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 330.3ms\nSpeed: 4.0ms preprocess, 330.3ms inference, 18.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 331.7ms\nSpeed: 6.0ms preprocess, 331.7ms inference, 17.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 338.3ms\nSpeed: 5.0ms preprocess, 338.3ms inference, 17.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 355.1ms\nSpeed: 8.0ms preprocess, 355.1ms inference, 16.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 347.3ms\nSpeed: 4.0ms preprocess, 347.3ms inference, 16.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 348.5ms\nSpeed: 5.0ms preprocess, 348.5ms inference, 16.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 341.3ms\nSpeed: 5.1ms preprocess, 341.3ms inference, 15.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 328.3ms\nSpeed: 3.0ms preprocess, 328.3ms inference, 17.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 333.8ms\nSpeed: 6.0ms preprocess, 333.8ms inference, 18.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 337.0ms\nSpeed: 6.0ms preprocess, 337.0ms inference, 15.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 350.3ms\nSpeed: 5.0ms preprocess, 350.3ms inference, 20.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 332.7ms\nSpeed: 6.0ms preprocess, 332.7ms inference, 20.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 332.4ms\nSpeed: 6.0ms preprocess, 332.4ms inference, 16.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 358.9ms\nSpeed: 6.0ms preprocess, 358.9ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 338.7ms\nSpeed: 5.9ms preprocess, 338.7ms inference, 17.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 336.8ms\nSpeed: 6.0ms preprocess, 336.8ms inference, 17.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 343.6ms\nSpeed: 6.0ms preprocess, 343.6ms inference, 17.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 337.4ms\nSpeed: 4.0ms preprocess, 337.4ms inference, 14.2ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 4 Potholes, 345.3ms\nSpeed: 5.0ms preprocess, 345.3ms inference, 17.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 359.9ms\nSpeed: 6.0ms preprocess, 359.9ms inference, 17.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 331.3ms\nSpeed: 6.0ms preprocess, 331.3ms inference, 17.5ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 357.4ms\nSpeed: 6.0ms preprocess, 357.4ms inference, 15.6ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 357.2ms\nSpeed: 5.0ms preprocess, 357.2ms inference, 15.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 3 Potholes, 369.6ms\nSpeed: 6.0ms preprocess, 369.6ms inference, 17.5ms postprocess per image at shape (1, 3, 512, 512)\n\n\n\n\nDetection\n\nimport cv2\n\nvideo_path = \"train/rgb/0215.mp4\"\ncap = cv2.VideoCapture(video_path)\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Call YOLO model for output and get the output\n    results = model.predict(frame)\n    \n    # Manipulate boxes in predictions\n    for result in results:\n        for bbox in result.boxes.xyxy:\n            # Kutuyu iÅaretle\n            x1, y1, x2, y2 = map(int, bbox)\n            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n            text = f\"Class: Pothole\"\n            cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n            \n    cv2.imshow(\"YOLOv8e Object Detection\", frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n\n\n0: 512x512 1 Pothole, 234.5ms\nSpeed: 4.1ms preprocess, 234.5ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 271.8ms\nSpeed: 4.0ms preprocess, 271.8ms inference, 6.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 270.6ms\nSpeed: 4.0ms preprocess, 270.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 331.3ms\nSpeed: 5.0ms preprocess, 331.3ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 252.6ms\nSpeed: 4.0ms preprocess, 252.6ms inference, 4.1ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 246.4ms\nSpeed: 4.0ms preprocess, 246.4ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 248.3ms\nSpeed: 6.4ms preprocess, 248.3ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 237.5ms\nSpeed: 4.0ms preprocess, 237.5ms inference, 2.9ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 244.9ms\nSpeed: 4.0ms preprocess, 244.9ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 222.4ms\nSpeed: 3.6ms preprocess, 222.4ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 1 Pothole, 241.2ms\nSpeed: 5.5ms preprocess, 241.2ms inference, 4.2ms postprocess per image at shape (1, 3, 512, 512)\n\n0: 512x512 2 Potholes, 222.7ms\nSpeed: 3.2ms preprocess, 222.7ms inference, 6.2ms postprocess per image at shape (1, 3, 512, 512)\n\n\n\nHacettepe University @2024;",
    "crumbs": [
      "Pothole Detection 1"
    ]
  },
  {
    "objectID": "potholedetection.html",
    "href": "potholedetection.html",
    "title": "Pothole Detection 2",
    "section": "",
    "text": "! pip install -q kaggle\n# kaggle.json\nfrom google.colab import files\nfiles.upload()\n\n\n! mkdir ~/.kaggle\n! cp kaggle.json ~/.kaggle/\n! chmod 600 ~/.kaggle/kaggle.json\n\n\n!rm -rf dataset\n\n\n# Download and unzip the Video Dataset\n!wget https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/5bwfg4v4cd-1.zip -O video_dataset.zip\n!unzip -q video_dataset.zip -d /content/video_dataset\n\n--2024-06-05 07:55:33--  https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/5bwfg4v4cd-1.zip\nResolving prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)... 52.92.0.210, 52.92.19.202, 3.5.70.120, ...\nConnecting to prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)|52.92.0.210|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1025803823 (978M) [application/zip]\nSaving to: âvideo_dataset.zipâ\n\nvideo_dataset.zip   100%[===================&gt;] 978.28M  24.0MB/s    in 40s     \n\n2024-06-05 07:56:14 (24.4 MB/s) - âvideo_dataset.zipâ saved [1025803823/1025803823]\n\n\n\n\n# Download and unzip the Pothole Image Segmentation Dataset from Kaggle\n!kaggle datasets download farzadnekouei/pothole-image-segmentation-dataset\n!unzip -q pothole-image-segmentation-dataset.zip -d /content/pothole_image_segmentation_dataset\n!unzip -q /content/video_dataset/Pothole\\ Videos/pothole_video.zip -d /content/video_dataset/Pothole\\ Videos\n\nDataset URL: https://www.kaggle.com/datasets/farzadnekouei/pothole-image-segmentation-dataset\nLicense(s): Apache 2.0\nDownloading pothole-image-segmentation-dataset.zip to /content\n 81% 48.0M/59.3M [00:00&lt;00:00, 122MB/s] \n100% 59.3M/59.3M [00:00&lt;00:00, 82.9MB/s]\n\n\n\n# Download and unzip the Pothole Detection Dataset from Kaggle\n!kaggle datasets download atulyakumar98/pothole-detection-dataset\n!unzip -q pothole-detection-dataset.zip -d /content/pothole_detection_dataset\n\nDataset URL: https://www.kaggle.com/datasets/atulyakumar98/pothole-detection-dataset\nLicense(s): CC0-1.0\nDownloading pothole-detection-dataset.zip to /content\n 98% 191M/194M [00:01&lt;00:00, 123MB/s]\n100% 194M/194M [00:01&lt;00:00, 114MB/s]\n\n\n\n!ls /content/video_dataset/Pothole\\ Videos/pothole_video\n!ls /content/pothole_image_segmentation_dataset/Pothole_Segmentation_YOLOv8\n!ls /content/pothole_detection_dataset\n\ntest  train  val\ndata.yaml  README.dataset.txt  README.roboflow.txt  sample_video.mp4  train  valid\nnormal  potholes",
    "crumbs": [
      "Pothole Detection 2"
    ]
  },
  {
    "objectID": "potholedetection.html#dataset-preparation",
    "href": "potholedetection.html#dataset-preparation",
    "title": "Pothole Detection 2",
    "section": "",
    "text": "! pip install -q kaggle\n# kaggle.json\nfrom google.colab import files\nfiles.upload()\n\n\n! mkdir ~/.kaggle\n! cp kaggle.json ~/.kaggle/\n! chmod 600 ~/.kaggle/kaggle.json\n\n\n!rm -rf dataset\n\n\n# Download and unzip the Video Dataset\n!wget https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/5bwfg4v4cd-1.zip -O video_dataset.zip\n!unzip -q video_dataset.zip -d /content/video_dataset\n\n--2024-06-05 07:55:33--  https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/5bwfg4v4cd-1.zip\nResolving prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)... 52.92.0.210, 52.92.19.202, 3.5.70.120, ...\nConnecting to prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)|52.92.0.210|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1025803823 (978M) [application/zip]\nSaving to: âvideo_dataset.zipâ\n\nvideo_dataset.zip   100%[===================&gt;] 978.28M  24.0MB/s    in 40s     \n\n2024-06-05 07:56:14 (24.4 MB/s) - âvideo_dataset.zipâ saved [1025803823/1025803823]\n\n\n\n\n# Download and unzip the Pothole Image Segmentation Dataset from Kaggle\n!kaggle datasets download farzadnekouei/pothole-image-segmentation-dataset\n!unzip -q pothole-image-segmentation-dataset.zip -d /content/pothole_image_segmentation_dataset\n!unzip -q /content/video_dataset/Pothole\\ Videos/pothole_video.zip -d /content/video_dataset/Pothole\\ Videos\n\nDataset URL: https://www.kaggle.com/datasets/farzadnekouei/pothole-image-segmentation-dataset\nLicense(s): Apache 2.0\nDownloading pothole-image-segmentation-dataset.zip to /content\n 81% 48.0M/59.3M [00:00&lt;00:00, 122MB/s] \n100% 59.3M/59.3M [00:00&lt;00:00, 82.9MB/s]\n\n\n\n# Download and unzip the Pothole Detection Dataset from Kaggle\n!kaggle datasets download atulyakumar98/pothole-detection-dataset\n!unzip -q pothole-detection-dataset.zip -d /content/pothole_detection_dataset\n\nDataset URL: https://www.kaggle.com/datasets/atulyakumar98/pothole-detection-dataset\nLicense(s): CC0-1.0\nDownloading pothole-detection-dataset.zip to /content\n 98% 191M/194M [00:01&lt;00:00, 123MB/s]\n100% 194M/194M [00:01&lt;00:00, 114MB/s]\n\n\n\n!ls /content/video_dataset/Pothole\\ Videos/pothole_video\n!ls /content/pothole_image_segmentation_dataset/Pothole_Segmentation_YOLOv8\n!ls /content/pothole_detection_dataset\n\ntest  train  val\ndata.yaml  README.dataset.txt  README.roboflow.txt  sample_video.mp4  train  valid\nnormal  potholes",
    "crumbs": [
      "Pothole Detection 2"
    ]
  },
  {
    "objectID": "potholedetection.html#data-preparation",
    "href": "potholedetection.html#data-preparation",
    "title": "Pothole Detection 2",
    "section": "Data Preparation",
    "text": "Data Preparation\n\n!pip install -U ultralytics==8.0.58\n\n\nimport os\nimport cv2\nimport numpy as np\nfrom ultralytics import YOLO\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom torchvision import transforms\nfrom PIL import Image\n\n\nVideo Dataset\n\nclass VideoDataset(Dataset):\n    def __init__(self, video_dir, mask_dir):\n        self.video_files = sorted(os.listdir(video_dir))\n        self.mask_files = sorted(os.listdir(mask_dir))\n        self.video_dir = video_dir\n        self.mask_dir = mask_dir\n\n    def __len__(self):\n        return len(self.video_files)\n\n    def __getitem__(self, idx):\n        video_path = os.path.join(self.video_dir, self.video_files[idx])\n        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n\n        video = cv2.VideoCapture(video_path)\n        mask = cv2.VideoCapture(mask_path)\n\n        frames = []\n        mask_frames = []\n        while(video.isOpened()):\n            ret, frame = video.read()\n            ret_mask, mask_frame = mask.read()\n            if ret and ret_mask:\n                frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n                mask_frames.append(mask_frame)\n            else:\n                break\n\n        video.release()\n        mask.release()\n\n        return np.array(frames), np.array(mask_frames)\n\ndef create_video_dataloader(video_dir, mask_dir, batch_size=4):\n    dataset = VideoDataset(video_dir, mask_dir)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    return dataloader\n\ntrain_video_dir = '/content/video_dataset/Pothole Videos/pothole_video/train/rgb'\ntrain_mask_dir = '/content/video_dataset/Pothole Videos/pothole_video/train/mask'\n\nval_video_dir = '/content/video_dataset/Pothole Videos/pothole_video/val/rgb'\nval_mask_dir = '/content/video_dataset/Pothole Videos/pothole_video/val/mask'\n\ntest_video_dir = '/content/video_dataset/Pothole Videos/pothole_video/test/rgb'\ntest_mask_dir = '/content/video_dataset/Pothole Videos/pothole_video/test/mask'\n\ntrain_dataloader = create_video_dataloader(train_video_dir, train_mask_dir)\nval_dataloader = create_video_dataloader(val_video_dir, val_mask_dir)\ntest_dataloader = create_video_dataloader(test_video_dir, test_mask_dir)\n\n\n\nPothole Image Segmentation Dataset\n\nsegmentation_dataset_path = '/content/pothole_image_segmentation_dataset/Pothole_Segmentation_YOLOv8'\n\nmodel = YOLO('yolov8n-seg.pt')\nyaml_path = os.path.join(segmentation_dataset_path, 'data.yaml')\n\nmodel.train(data=yaml_path, epochs=10, imgsz=640, seed=42)\n\nDownloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-seg.pt to yolov8n-seg.pt...\n100%|ââââââââââ| 6.73M/6.73M [00:00&lt;00:00, 118MB/s]\nNew https://pypi.org/project/ultralytics/8.2.28 available ð Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.58 ð Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\nyolo/engine/trainer: task=segment, mode=train, model=yolov8n-seg.pt, data=/content/pothole_image_segmentation_dataset/Pothole_Segmentation_YOLOv8/data.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=42, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/segment/train\nDownloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n100%|ââââââââââ| 755k/755k [00:00&lt;00:00, 25.9MB/s]\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n 22        [15, 18, 21]  1   1004275  ultralytics.nn.modules.Segment               [1, 32, 64, [64, 128, 256]]   \nYOLOv8n-seg summary: 261 layers, 3263811 parameters, 3263795 gradients, 12.1 GFLOPs\n\nTransferred 381/417 items from pretrained weights\nTensorBoard: Start with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\nAMP: running Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n100%|ââââââââââ| 6.23M/6.23M [00:00&lt;00:00, 126MB/s]\n/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n  return F.conv2d(input, weight, bias, self.stride,\nWARNING â ï¸ NMS time limit 0.550s exceeded\nAMP: checks passed â\noptimizer: SGD(lr=0.01) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias\ntrain: Scanning /content/pothole_image_segmentation_dataset/Pothole_Segmentation_YOLOv8/train/labels... 720 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 720/720 [00:01&lt;00:00, 477.54it/s]\ntrain: New cache created: /content/pothole_image_segmentation_dataset/Pothole_Segmentation_YOLOv8/train/labels.cache\nalbumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\nval: Scanning /content/pothole_image_segmentation_dataset/Pothole_Segmentation_YOLOv8/valid/labels... 60 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 60/60 [00:00&lt;00:00, 423.85it/s]\nval: New cache created: /content/pothole_image_segmentation_dataset/Pothole_Segmentation_YOLOv8/valid/labels.cache\nPlotting labels to runs/segment/train/labels.jpg... \nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to runs/segment/train\nStarting training for 10 epochs...\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nClosing dataloader mosaic\nalbumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       1/10      3.05G      1.567      3.545      3.262      1.565         23        640: 100%|ââââââââââ| 45/45 [00:28&lt;00:00,  1.58it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:02&lt;00:00,  1.01s/it]\n                   all         60        201     0.0085      0.761      0.124     0.0594    0.00828      0.741      0.119      0.056\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       2/10      3.47G      1.411      2.557      2.232       1.44         35        640: 100%|ââââââââââ| 45/45 [00:21&lt;00:00,  2.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:01&lt;00:00,  1.10it/s]\n                   all         60        201      0.725      0.302      0.488      0.257      0.747      0.303      0.482      0.231\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       3/10      3.47G      1.402      2.373      1.895      1.405         34        640: 100%|ââââââââââ| 45/45 [00:19&lt;00:00,  2.26it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:01&lt;00:00,  1.20it/s]\n                   all         60        201      0.557      0.338      0.382      0.199      0.547      0.313      0.361      0.179\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       4/10      3.47G      1.398      2.333      1.738      1.388         34        640: 100%|ââââââââââ| 45/45 [00:20&lt;00:00,  2.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:02&lt;00:00,  1.29s/it]\n                   all         60        201      0.599      0.453      0.496      0.252      0.601      0.448      0.487      0.242\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       5/10      3.47G      1.353      2.213      1.645      1.368         29        640: 100%|ââââââââââ| 45/45 [00:20&lt;00:00,  2.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:01&lt;00:00,  1.17it/s]\n                   all         60        201      0.616      0.662       0.63      0.351      0.628      0.667       0.63      0.337\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       6/10      3.47G      1.353       2.15      1.544      1.344         50        640: 100%|ââââââââââ| 45/45 [00:20&lt;00:00,  2.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:02&lt;00:00,  1.25s/it]\n                   all         60        201       0.58      0.483      0.541       0.25      0.564      0.473      0.482      0.212\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       7/10      3.47G      1.318      2.065      1.467      1.343         21        640: 100%|ââââââââââ| 45/45 [00:20&lt;00:00,  2.14it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:01&lt;00:00,  1.14it/s]\n                   all         60        201      0.627      0.716       0.66      0.355      0.628      0.716      0.665      0.345\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       8/10      3.47G      1.274      1.989      1.377      1.296         37        640: 100%|ââââââââââ| 45/45 [00:20&lt;00:00,  2.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:02&lt;00:00,  1.23s/it]\n                   all         60        201      0.564      0.637      0.627      0.341      0.568      0.641      0.635      0.333\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       9/10      3.47G      1.237      1.893      1.279      1.268         33        640: 100%|ââââââââââ| 45/45 [00:23&lt;00:00,  1.90it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:01&lt;00:00,  1.12it/s]\n                   all         60        201      0.698      0.617      0.667      0.379      0.678      0.667      0.697      0.365\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n      10/10      3.47G      1.168      1.784      1.227      1.212         40        640: 100%|ââââââââââ| 45/45 [00:23&lt;00:00,  1.88it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:03&lt;00:00,  1.85s/it]\n                   all         60        201      0.658      0.757      0.761      0.442      0.662      0.759      0.754      0.416\n\n10 epochs completed in 0.071 hours.\nOptimizer stripped from runs/segment/train/weights/last.pt, 6.8MB\nOptimizer stripped from runs/segment/train/weights/best.pt, 6.8MB\n\nValidating runs/segment/train/weights/best.pt...\nUltralytics YOLOv8.0.58 ð Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:952: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n  return F.conv_transpose2d(\nYOLOv8n-seg summary (fused): 195 layers, 3258259 parameters, 0 gradients, 12.0 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00&lt;?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:03&lt;00:00,  1.75s/it]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:03&lt;00:00,  1.99s/it]\n                   all         60        201      0.664      0.766      0.764      0.444      0.664      0.766      0.754      0.417\nSpeed: 0.3ms preprocess, 3.7ms inference, 0.0ms loss, 4.2ms postprocess per image\nResults saved to runs/segment/train\n\n\n\n\nPothole Detection Dataset\n\nclass PotholeDetectionDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_files = []\n        self.labels = []\n\n        for label in ['normal', 'potholes']:\n            folder = os.path.join(root_dir, label)\n            for img_file in os.listdir(folder):\n                self.image_files.append(os.path.join(folder, img_file))\n                self.labels.append(0 if label == 'normal' else 1)\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        img_path = self.image_files[idx]\n        image = Image.open(img_path).convert('RGB')\n        label = self.labels[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\ntransform = transforms.Compose([\n    transforms.Resize((640, 640)),\n    transforms.ToTensor(),\n])\n\ndetection_dataset_path = '/content/pothole_detection_dataset'\ndetection_dataset = PotholeDetectionDataset(detection_dataset_path, transform=transform)\ndetection_dataloader = DataLoader(detection_dataset, batch_size=16, shuffle=True)",
    "crumbs": [
      "Pothole Detection 2"
    ]
  },
  {
    "objectID": "potholedetection.html#training",
    "href": "potholedetection.html#training",
    "title": "Pothole Detection 2",
    "section": "Training",
    "text": "Training\n\ndef combined_training(model, train_dataloader, val_dataloader, detection_dataloader, epochs=10):\n    best_loss = float('inf')\n    best_model_path = '/content/best_pothole_detection_model.pt'\n\n    for epoch in range(epochs):\n        model.train()\n\n        # Train on video data\n        for video_batch in train_dataloader:\n            videos, masks = video_batch\n            model.train_step(videos, masks)\n\n        # Train on image data\n        for image_batch in val_dataloader:\n            images, masks = image_batch\n            model.train_step(images, masks)\n\n        # Train on detection data\n        for detection_batch in detection_dataloader:\n            images, labels = detection_batch\n            model.train_step(images, labels)\n\n        # Validate the model\n        val_loss = 0\n        model.eval()\n        with torch.no_grad():\n            # Validate on video data\n            for val_video_batch in val_dataloader:\n                val_videos, val_masks = val_video_batch\n                val_loss += model.val_step(val_videos, val_masks)\n\n            # Validate on image data\n            for val_image_batch in val_dataloader:\n                val_images, val_masks = val_image_batch\n                val_loss += model.val_step(val_images, val_masks)\n\n            # Validate on detection data\n            for val_detection_batch in detection_dataloader:\n                val_images, val_labels = val_detection_batch\n                val_loss += model.val_step(val_images, val_labels)\n\n        # Save the best model\n        if val_loss &lt; best_loss:\n            best_loss = val_loss\n            model.save(best_model_path)\n\n# Perform combined training\ncombined_training(model, train_dataloader, val_dataloader, detection_dataloader)\n\nNew https://pypi.org/project/ultralytics/8.2.28 available ð Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.58 ð Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\nyolo/engine/trainer: task=segment, mode=train, model=yolov8n-seg.pt, data=/content/pothole_image_segmentation_dataset/Pothole_Segmentation_YOLOv8/data.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=42, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/segment/train2\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n 22        [15, 18, 21]  1   1004275  ultralytics.nn.modules.Segment               [1, 32, 64, [64, 128, 256]]   \nYOLOv8n-seg summary: 261 layers, 3263811 parameters, 3263795 gradients, 12.1 GFLOPs\n\nTransferred 417/417 items from pretrained weights\nTensorBoard: Start with 'tensorboard --logdir runs/segment/train2', view at http://localhost:6006/\nAMP: running Automatic Mixed Precision (AMP) checks with YOLOv8n...\nAMP: checks passed â\noptimizer: SGD(lr=0.01) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias\ntrain: Scanning /content/pothole_image_segmentation_dataset/Pothole_Segmentation_YOLOv8/train/labels.cache... 720 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 720/720 [00:00&lt;?, ?it/s]\nalbumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\nval: Scanning /content/pothole_image_segmentation_dataset/Pothole_Segmentation_YOLOv8/valid/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 60/60 [00:00&lt;?, ?it/s]\nPlotting labels to runs/segment/train2/labels.jpg... \nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to runs/segment/train2\nStarting training for 10 epochs...\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nClosing dataloader mosaic\nalbumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n  0%|          | 0/45 [00:00&lt;?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n       1/10      2.95G      1.135      1.722      1.102      1.195         23        640: 100%|ââââââââââ| 45/45 [00:23&lt;00:00,  1.92it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:01&lt;00:00,  1.11it/s]\n                   all         60        201      0.653      0.731      0.733      0.424      0.649      0.726      0.725       0.41\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       2/10      3.36G      1.139      1.713      1.081      1.192         35        640: 100%|ââââââââââ| 45/45 [00:22&lt;00:00,  2.01it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:01&lt;00:00,  1.10it/s]\n                   all         60        201      0.705      0.713      0.696      0.385      0.704      0.697      0.693      0.366\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       3/10      3.36G      1.178      1.747      1.123      1.215         34        640: 100%|ââââââââââ| 45/45 [00:19&lt;00:00,  2.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:01&lt;00:00,  1.15it/s]\n                   all         60        201       0.63      0.677      0.689      0.373      0.619      0.677      0.671      0.344\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       4/10      3.36G      1.169      1.769      1.117       1.22         34        640: 100%|ââââââââââ| 45/45 [00:22&lt;00:00,  2.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:01&lt;00:00,  1.07it/s]\n                   all         60        201      0.644      0.602      0.556      0.318      0.655      0.612      0.575      0.297\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       5/10      3.36G       1.15      1.753       1.07      1.205         29        640: 100%|ââââââââââ| 45/45 [00:20&lt;00:00,  2.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:01&lt;00:00,  1.14it/s]\n                   all         60        201      0.727      0.527      0.612      0.348      0.754      0.547      0.636      0.327\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       6/10      3.36G      1.164      1.786      1.085      1.208         50        640: 100%|ââââââââââ| 45/45 [00:21&lt;00:00,  2.05it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:02&lt;00:00,  1.09s/it]\n                   all         60        201      0.686      0.627      0.649      0.357      0.697      0.641      0.665      0.351\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       7/10      3.36G       1.12      1.694      1.036      1.195         21        640: 100%|ââââââââââ| 45/45 [00:19&lt;00:00,  2.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:02&lt;00:00,  1.09s/it]\n                   all         60        201      0.692      0.642      0.671      0.387      0.704      0.652      0.683      0.376\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       8/10      3.36G      1.116      1.665     0.9883      1.178         37        640: 100%|ââââââââââ| 45/45 [00:23&lt;00:00,  1.92it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:01&lt;00:00,  1.06it/s]\n                   all         60        201      0.783      0.542      0.711       0.41      0.765      0.572      0.714       0.41\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n       9/10      3.36G      1.082      1.611     0.9206      1.151         33        640: 100%|ââââââââââ| 45/45 [00:19&lt;00:00,  2.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:01&lt;00:00,  1.13it/s]\n                   all         60        201      0.682      0.701      0.695        0.4      0.688      0.701      0.706      0.375\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n      10/10      3.36G      1.039      1.536     0.9006      1.119         40        640: 100%|ââââââââââ| 45/45 [00:21&lt;00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:03&lt;00:00,  1.90s/it]\n                   all         60        201       0.69      0.672       0.73      0.442      0.702      0.682      0.734       0.42\n\n10 epochs completed in 0.070 hours.\nOptimizer stripped from runs/segment/train2/weights/last.pt, 6.8MB\nOptimizer stripped from runs/segment/train2/weights/best.pt, 6.8MB\n\nValidating runs/segment/train2/weights/best.pt...\nUltralytics YOLOv8.0.58 ð Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\nYOLOv8n-seg summary (fused): 195 layers, 3258259 parameters, 0 gradients, 12.0 GFLOPs\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00&lt;?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:03&lt;00:00,  1.72s/it]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 2/2 [00:03&lt;00:00,  1.96s/it]\n                   all         60        201      0.679      0.694       0.73      0.443      0.702      0.682      0.734       0.42\nSpeed: 0.2ms preprocess, 3.5ms inference, 0.0ms loss, 3.7ms postprocess per image\nResults saved to runs/segment/train2\n\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n&lt;ipython-input-14-1780ed4d1afe&gt; in &lt;cell line: 48&gt;()\n     46 \n     47 # Perform combined training\n---&gt; 48 combined_training(model, train_dataloader, val_dataloader, detection_dataloader)\n\n&lt;ipython-input-14-1780ed4d1afe&gt; in combined_training(model, train_dataloader, val_dataloader, detection_dataloader, epochs)\n      9         for video_batch in train_dataloader:\n     10             videos, masks = video_batch\n---&gt; 11             model.train_step(videos, masks)\n     12 \n     13         # Train on image data\n\n/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/model.py in __getattr__(self, attr)\n    103     def __getattr__(self, attr):\n    104         name = self.__class__.__name__\n--&gt; 105         raise AttributeError(f\"'{name}' object has no attribute '{attr}'. See valid attributes below.\\n{self.__doc__}\")\n    106 \n    107     def _new(self, cfg: str, task=None, verbose=True):\n\nAttributeError: 'YOLO' object has no attribute 'train_step'. See valid attributes below.\n\n    YOLO (You Only Look Once) object detection model.\n\n    Args:\n        model (str, Path): Path to the model file to load or create.\n\n    Attributes:\n        predictor (Any): The predictor object.\n        model (Any): The model object.\n        trainer (Any): The trainer object.\n        task (str): The type of model task.\n        ckpt (Any): The checkpoint object if the model loaded from *.pt file.\n        cfg (str): The model configuration if loaded from *.yaml file.\n        ckpt_path (str): The checkpoint file path.\n        overrides (dict): Overrides for the trainer object.\n        metrics (Any): The data for metrics.\n\n    Methods:\n        __call__(source=None, stream=False, **kwargs):\n            Alias for the predict method.\n        _new(cfg:str, verbose:bool=True) -&gt; None:\n            Initializes a new model and infers the task type from the model definitions.\n        _load(weights:str, task:str='') -&gt; None:\n            Initializes a new model and infers the task type from the model head.\n        _check_is_pytorch_model() -&gt; None:\n            Raises TypeError if the model is not a PyTorch model.\n        reset() -&gt; None:\n            Resets the model modules.\n        info(verbose:bool=False) -&gt; None:\n            Logs the model info.\n        fuse() -&gt; None:\n            Fuses the model for faster inference.\n        predict(source=None, stream=False, **kwargs) -&gt; List[ultralytics.yolo.engine.results.Results]:\n            Performs prediction using the YOLO model.\n\n    Returns:\n        list(ultralytics.yolo.engine.results.Results): The prediction results.\n    \n\n\n\n\ndef calculate_iou(pred, target, threshold=0.5):\n    pred = (pred &gt; threshold).astype(np.uint8)\n    intersection = np.logical_and(pred, target)\n    union = np.logical_or(pred, target)\n    iou_score = np.sum(intersection) / np.sum(union)\n    return iou_score\n\ndef calculate_pixel_accuracy(pred, target, threshold=0.5):\n    pred = (pred &gt; threshold).astype(np.uint8)\n    correct = np.sum(pred == target)\n    total = target.size\n    accuracy = correct / total\n    return accuracy\n\n\nclass PotholeDetectionEvaluator:\n    def __init__(self, model, test_dataloader):\n        self.model = model\n        self.test_dataloader = test_dataloader\n\n    def evaluate(self):\n        total_iou = 0\n        total_accuracy = 0\n        total_videos = 0\n\n        self.model.eval()\n        with torch.no_grad():\n            for test_batch in self.test_dataloader:\n                test_videos, test_masks = test_batch\n                for video, mask in zip(test_videos, test_masks):\n                    predictions = self.model.predict(video)\n                    iou_scores = []\n                    accuracies = []\n\n                    for pred_frame, mask_frame in zip(predictions, mask):\n                        iou = calculate_iou(pred_frame, mask_frame)\n                        accuracy = calculate_pixel_accuracy(pred_frame, mask_frame)\n                        iou_scores.append(iou)\n                        accuracies.append(accuracy)\n\n                    avg_iou = np.mean(iou_scores)\n                    avg_accuracy = np.mean(accuracies)\n\n                    total_iou += avg_iou\n                    total_accuracy += avg_accuracy\n                    total_videos += 1\n\n        avg_iou = total_iou / total_videos\n        avg_accuracy = total_accuracy / total_videos\n        print(f\"Average IoU: {avg_iou:.4f}\")\n        print(f\"Average Pixel Accuracy: {avg_accuracy:.4f}\")\n\nevaluator = PotholeDetectionEvaluator(best_model, test_dataloader)\n\nevaluator.evaluate()",
    "crumbs": [
      "Pothole Detection 2"
    ]
  }
]